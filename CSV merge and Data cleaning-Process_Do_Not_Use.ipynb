{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicole's code starts here \n",
    "# Importing \"The Numbers\" data & cleaning it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import OMB_api_key\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_df = pd.read_csv('DataFiles/TheNumbers_Original.csv')\n",
    "print(numbers_df.shape)\n",
    "numbers_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create month released column & add to dataframe. Probably don't need to do this since we can\n",
    "# return the month after turning it into a datetime data type\n",
    "numbers_df['Domestic Release Date'] = numbers_df['Domestic Release Date'].astype('datetime64[ns]')\n",
    "numbers_df['Worldwide Release Date'] = numbers_df['Worldwide Release Date'].astype('datetime64[ns]')\n",
    "month = pd.DatetimeIndex(numbers_df['Domestic Release Date']).month\n",
    "numbers_df.insert(3, 'Month Released (Domestic)', month)\n",
    "numbers_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns 11 + to integer\n",
    "numbers_df[numbers_df.columns[11:]] = numbers_df[numbers_df.columns[11:]].apply\\\n",
    "(lambda x: x.str.replace('$','')).apply(lambda x: x.str.replace(',','')).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding available oscar count per year. Somebody please check these calculations if we use this!\n",
    "numbers_df['Total Oscars Awarded in Year'] = ''\n",
    "for index, row in numbers_df.iterrows():\n",
    "    year = row['Year Released (Domestic)']\n",
    "    if year == 1980:\n",
    "        numbers_df.loc[index, 'Total Oscars Awarded in Year'] = 22\n",
    "    elif year in range(1981,1995) or year == 1999:\n",
    "        numbers_df.loc[index, 'Total Oscars Awarded in Year'] = 23\n",
    "    elif year in range(2001,2020):\n",
    "        numbers_df.loc[index, 'Total Oscars Awarded in Year'] = 25\n",
    "    else:\n",
    "        numbers_df.loc[index, 'Total Oscars Awarded in Year'] = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title needs cleaning (remove apostrophes, colons, eplipses, \"Ep. xxx:\")\n",
    "# The order it is replaced is sequential (ie: relacing Ep. I, followd by Ep. II returns I)\n",
    "\n",
    "# Creating new title column so we can use original title later\n",
    "numbers_df.insert(6, 'Query_Title', numbers_df['Title'])\n",
    "\n",
    "# Replacing characters\n",
    "numbers_df[numbers_df.columns[6:7]] = numbers_df[numbers_df.columns[6:7]].apply\\\n",
    "(lambda x: x.str.replace(\":\",'')).apply(lambda x: x.str.replace(\"Ep.\",\"Episode\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Limit movies to 40 per year - defined as top 40 by adjusted gross ***\n",
    "numbers_df = numbers_df.sort_values(['Year Released (Domestic)', 'Infl. Adj. Dom. Box Office'],\n",
    "                                    ascending = [True, False])\n",
    "numbers_df = numbers_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still limiting...\n",
    "numbers_df['Year Index'] = ''\n",
    "year_compare = 1980\n",
    "count = 0\n",
    "for index, row in numbers_df.iterrows():\n",
    "    year = row['Year Released (Domestic)']\n",
    "    if year == year_compare:\n",
    "        count += 1\n",
    "        numbers_df.loc[index, 'Year Index'] = count\n",
    "    else:\n",
    "        count = 1\n",
    "        numbers_df.loc[index, 'Year Index'] = count\n",
    "        year_compare += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ... a little more & voila!\n",
    "top_40_df = numbers_df.loc[(numbers_df['Year Index'] <=40), ['Title', 'Query_Title',\n",
    "                                                             'Domestic Release Date',\n",
    "                                                             'Year Released (Domestic)',\n",
    "                                                             'Month Released (Domestic)',\n",
    "                                                             'Infl. Adj. Dom. Box Office',\n",
    "                                                             'Domestic Box Office',\n",
    "                                                             'Genre', 'Theatrical Distributor',\n",
    "                                                             'Total Oscars Awarded in Year']]\n",
    "top_40_df = top_40_df.sort_values('Infl. Adj. Dom. Box Office', ascending = False)\n",
    "top_40_df = top_40_df.reset_index(drop = True)\n",
    "top_40_df.to_csv('DataFiles/TheNumbers_Cleaned.csv')\n",
    "print(top_40_df.shape)\n",
    "top_40_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********  This is the end of data_cleaning & start of request tests ***********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUEST TESTING (Okay to remove cell)\n",
    "# Sample JSON in case you want to run one specific movie title\n",
    "# movie_title = \"The battle of the five armies\"\n",
    "# params = {'type': 'movie', 'apikey': OMB_api_key, 't': movie_title}\n",
    "# url = 'http://www.omdbapi.com/?t='\n",
    "# response = requests.get(url, params).json()\n",
    "# pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUEST TESTING (Okay to remove cell)\n",
    "# Subset dataframe for request testing\n",
    "# test_subset = omdb_df.iloc[25:39, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUEST TESTING (Okay to remove cell)\n",
    "# Testing Requests on subset.\n",
    "# If one of the values within a found movie is missing, it stops inputting data into DF after that\n",
    "#     and I told it to print that so we know (uncomment the metascore row to view this)\n",
    "# If we find a lot of missing movies, we could look into adding a year parameter.\n",
    "#     It looks like it returns the first movie found (ie: 'Star Wars' returns 'Star Wars IV')\n",
    "\n",
    "# params = {\"type\": \"movie\", \"apikey\": OMB_api_key}\n",
    "# url = \"http://www.omdbapi.com/?t=\"\n",
    "# count = 0\n",
    "# for index, row in test_subset.iterrows():\n",
    "#     params[\"t\"] = row[\"Query_Title\"]\n",
    "#     response = requests.get(url, params).json()\n",
    "#     if response['Response'] == 'True':\n",
    "#         try:\n",
    "#             omdb_df.loc[index, 'Awards'] = response['Awards']\n",
    "#             omdb_df.loc[index, 'Metascore'] = response['Metascore']\n",
    "#             omdb_df.loc[index, 'IMDB'] = response['imdbRating']\n",
    "#             omdb_df.loc[index, 'Rotten Tomatoes'] = response['Ratings'][1]['Value']\n",
    "#             omdb_df.loc[index, 'Rated'] = response['Rated']\n",
    "#             omdb_df.loc[index, 'Director'] = response['Director']\n",
    "#             omdb_df.loc[index, 'Runtime'] = response['Runtime']\n",
    "#             omdb_df.loc[index, 'Country'] = response['Country']\n",
    "#         except:\n",
    "#             print(f'{row.Query_Title.upper()} (row {count}) has missing data')\n",
    "#         count += 1\n",
    "#     else:\n",
    "#         print(f'{row.Query_Title.upper()} (row {count}) was not found')\n",
    "#         count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** API requests All Data *****\n",
    "\n",
    "# params = {\"type\": \"movie\", \"apikey\": OMB_api_key}\n",
    "# url = \"http://www.omdbapi.com/?t=\"\n",
    "# count = 0\n",
    "# for index, row in omdb_df.iterrows():\n",
    "#     params['t'] = row[\"Query_Title\"]\n",
    "#     response = requests.get(url, params).json()\n",
    "#     if response['Response'] == 'True':\n",
    "#         try:\n",
    "#             omdb_df.loc[index, 'Awards'] = response['Awards']\n",
    "#             omdb_df.loc[index, 'Metascore'] = response['Metascore']\n",
    "#             omdb_df.loc[index, 'IMDB'] = response['imdbRating']\n",
    "#             omdb_df.loc[index, 'Rotten Tomatoes'] = response['Ratings'][1]['Value']\n",
    "#             omdb_df.loc[index, 'Rated'] = response['Rated']\n",
    "#             omdb_df.loc[index, 'Director'] = response['Director']\n",
    "#             omdb_df.loc[index, 'Runtime'] = response['Runtime']\n",
    "#             omdb_df.loc[index, 'Country'] = response['Country']\n",
    "#         except:\n",
    "#             print(f'{row.Query_Title.upper()} (row {count}) has missing data')\n",
    "#         count += 1\n",
    "#     else:\n",
    "#         print(f'{row.Query_Title.upper()} (row {count}) was not found')\n",
    "#         count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(omdb_df.shape)\n",
    "# omdb_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving what we have so far\n",
    "# omdb_df.to_csv('DataFiles/First_API_Run_BETA.csv', index=False)\n",
    "\n",
    "# Loading for demo purposes\n",
    "# omdb_df = pd.read_csv('DataFiles/First_API_Run_BETA.csv')\n",
    "# omdb_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicole's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NICOLE'S CLEAN-UP CODE STARTS HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating dataframe to hold subset request data\n",
    "# omdb_successes_df = top_40_df.copy()\n",
    "# omdb_successes_df['Awards'] = ''\n",
    "# omdb_successes_df['Metascore'] = ''\n",
    "# omdb_successes_df['IMDB'] = ''\n",
    "# omdb_successes_df['Rotten Tomatoes'] = ''\n",
    "# omdb_successes_df['Rated'] = ''\n",
    "# omdb_successes_df['Director'] = ''\n",
    "# omdb_successes_df['Runtime'] = ''\n",
    "# omdb_successes_df['Country'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ***** API requests All Data *****\n",
    "\n",
    "# params = {\"type\": \"movie\", \"apikey\": OMB_api_key}\n",
    "# url = \"http://www.omdbapi.com/?t=&y=\"\n",
    "# count = 0\n",
    "# for index, row in omdb_successes_df.iterrows():\n",
    "#     params[\"t\"] = row[\"Query_Title\"]\n",
    "#     params[\"y\"] = row[\"Year Released (Domestic)\"]\n",
    "#     response = requests.get(url, params).json()\n",
    "#     if response['Response'] == 'True':\n",
    "#         try:\n",
    "#             omdb_successes_df.loc[index, 'Awards'] = response['Awards']\n",
    "#             omdb_successes_df.loc[index, 'Metascore'] = response['Metascore']\n",
    "#             omdb_successes_df.loc[index, 'IMDB'] = response['imdbRating']\n",
    "#             omdb_successes_df.loc[index, 'Rotten Tomatoes'] = response['Ratings'][1]['Value']\n",
    "#             omdb_successes_df.loc[index, 'Rated'] = response['Rated']\n",
    "#             omdb_successes_df.loc[index, 'Director'] = response['Director']\n",
    "#             omdb_successes_df.loc[index, 'Runtime'] = response['Runtime']\n",
    "#             omdb_successes_df.loc[index, 'Country'] = response['Country']\n",
    "#         except:\n",
    "#             omdb_successes_df = omdb_successes_df.drop(count)\n",
    "#             print(f'{row.Query_Title.upper()} (row {count}) has missing data')\n",
    "#     else:\n",
    "#         print(f'{row.Query_Title.upper()} (row {count}) was not found')\n",
    "#         omdb_successes_df = omdb_successes_df.drop(count)\n",
    "#     count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing successes to file\n",
    "# omdb_successes_df.to_csv('DataFiles/OMDB_Successes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in Successes\n",
    "omdb_successes_df = pd.read_csv('DataFiles/OMDB_Successes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(omdb_successes_df.shape)\n",
    "omdb_successes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omdb_successes_df = omdb_successes_df.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(omdb_successes_df.shape)\n",
    "omdb_successes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omdb_failures_df = top_40_df[top_40_df['Title'].isin(omdb_successes_df['Title'])==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omdb_failures_df = omdb_failures_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(omdb_failures_df.shape)\n",
    "omdb_failures_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating identical columns\n",
    "omdb_failures_df = omdb_failures_df.copy()\n",
    "omdb_failures_df['Awards'] = ''\n",
    "omdb_failures_df['Metascore'] = ''\n",
    "omdb_failures_df['IMDB'] = ''\n",
    "omdb_failures_df['Rotten Tomatoes'] = ''\n",
    "omdb_failures_df['Rated'] = ''\n",
    "omdb_failures_df['Director'] = ''\n",
    "omdb_failures_df['Runtime'] = ''\n",
    "omdb_failures_df['Country'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overwrite cells with new query inputs\n",
    "omdb_failures_df.at[0,'Query_Title'] = \"DEAD MAN'S\"\n",
    "omdb_failures_df.at[1,'Query_Title'] = 'THE RISE OF SKYWALKER'\n",
    "omdb_failures_df.at[2,'Query_Title'] = 'THE CURSE OF'\n",
    "omdb_failures_df.at[3,'Query_Title'] = 'THE CHRONICLES OF NARNIA'\n",
    "omdb_failures_df.at[4,\"Query_Title\"] = \"PIRATES OF THE CARIBBEAN AT WORLD'S END\"\n",
    "omdb_failures_df.at[5,'Query_Title'] = 'HARRY POTTER AND THE ORDER OF THE PHOENIX'\n",
    "omdb_failures_df.at[6,'Query_Title'] = 'THREE MEN AND A BABY'\n",
    "omdb_failures_df.at[7,'Query_Title'] = 'MISSION IMPOSSIBLE II'\n",
    "omdb_failures_df.at[8,'Query_Title'] = '9 To 5'\n",
    "omdb_failures_df.at[9,'Query_Title'] = 'X-MEN'\n",
    "omdb_failures_df.at[10,'Query_Title'] = 'MEN IN BLACK'\n",
    "omdb_failures_df.at[11,'Query_Title'] = 'THE HOBBIT'\n",
    "omdb_failures_df.at[12,'Query_Title'] = 'DUMB AND DUMBER'\n",
    "omdb_failures_df.at[13,'Query_Title'] = 'THE GRINCH'\n",
    "omdb_failures_df.at[14,'Query_Title'] = 'FAST & FURIOUS 6'\n",
    "omdb_failures_df.at[15,'Query_Title'] = 'MR & MRS SMITH'\n",
    "omdb_failures_df.at[16,'Query_Title'] = 'THE LORAX'\n",
    "omdb_failures_df.at[17,'Query_Title'] = 'CROCODILE DUNDEE II'\n",
    "omdb_failures_df.at[18,'Query_Title'] = 'INTERVIEW WITH THE VAMPIRE'\n",
    "omdb_failures_df.at[19,'Query_Title'] = 'NIGHT AT THE MUSEUM BATTLE'\n",
    "omdb_failures_df.at[20,'Query_Title'] = 'SPIDER-MAN INTO THE SPIDER-VERSE'\n",
    "omdb_failures_df.at[21,'Query_Title'] = 'tt0089050'\n",
    "omdb_failures_df.at[22,'Query_Title'] = 'DEAD MEN TELL NO TALES'\n",
    "omdb_failures_df.at[23,'Query_Title'] = 'RISE OF THE SILVER SURFER'\n",
    "omdb_failures_df.at[24,'Query_Title'] = 'FROM THE FILES OF POLICE SQUAD'\n",
    "omdb_failures_df.at[25,'Query_Title'] = \"A SERIES OF UNFORTUNATE EVENTS\"\n",
    "omdb_failures_df.at[26,'Query_Title'] = 'DODGEBALL'\n",
    "omdb_failures_df.at[27,'Query_Title'] = 'A CHRISTMAS CAROL'\n",
    "omdb_failures_df.at[28,'Query_Title'] = 'X-FILES'\n",
    "omdb_failures_df.at[29,'Query_Title'] = 'FANTASTIC BEASTS'\n",
    "omdb_failures_df.at[30,'Query_Title'] = 'I NOW PRONOUNCE YOU CHUCK & LARRY'\n",
    "omdb_failures_df.at[31,'Query_Title'] = 'THREE MEN AND A LITTLE LADY'\n",
    "omdb_failures_df.at[32,'Query_Title'] = 'tt0087355'\n",
    "omdb_failures_df.at[33,'Query_Title'] = \"CHEECH AND CHONG'S NEXT MOVIE\"\n",
    "omdb_failures_df.at[34,'Query_Title'] = 'INSURGENT'\n",
    "omdb_failures_df.at[35,'Query_Title'] = 'LEGALLY BLONDE 2'\n",
    "omdb_failures_df.at[36,'Query_Title'] = 'tt0113676'\n",
    "omdb_failures_df.at[37,'Query_Title'] = 'ISLAND OF LOST DREAMS'\n",
    "omdb_failures_df.at[38,'Query_Title'] = 'BLADE II'\n",
    "omdb_failures_df.at[39,'Query_Title'] = 'ARTIFICIAL INTELLIGENCE'\n",
    "omdb_failures_df.at[40,'Query_Title'] = 'THE HANGOVER PART III'\n",
    "omdb_failures_df.at[41,'Query_Title'] = 'SPONGEBOB SQUAREPANTS MOVIE'\n",
    "omdb_failures_df.at[42,'Query_Title'] = 'GREYSTOKE'\n",
    "omdb_failures_df.at[43,'Query_Title'] = 'MOUSEHUNT'\n",
    "omdb_failures_df.at[44,'Query_Title'] = 'NICE DREAMS'\n",
    "omdb_failures_df.at[45,'Query_Title'] = 'tt0098484'\n",
    "omdb_failures_df.at[46,'Query_Title'] = 'MAMMA MIA! HERE WE GO AGAIN'\n",
    "omdb_failures_df.at[47,'Query_Title'] = 'EPIC'\n",
    "omdb_failures_df.at[48,'Query_Title'] = 'FANTASIA 2000'\n",
    "omdb_failures_df.at[49,'Query_Title'] = 'tt0370263'\n",
    "omdb_failures_df.at[50,'Query_Title'] = 'FORD V FERRARI'\n",
    "omdb_failures_df.at[51,'Query_Title'] = 'COWBOYS & ALIENS'\n",
    "omdb_failures_df.at[52,'Query_Title'] = 'HIGH SCHOOL MUSICAL 3'\n",
    "omdb_failures_df.at[53,'Query_Title'] = 'GNOMEO & JULIET'\n",
    "omdb_failures_df.at[54,'Query_Title'] = 'FRIDAY THE 13TH PART III'\n",
    "omdb_failures_df.at[55,'Query_Title'] = 'GARFIELD'\n",
    "omdb_failures_df.at[56,'Query_Title'] = \"MARCH OF THE PENGUINS\"\n",
    "omdb_failures_df.at[57,'Query_Title'] = 'A NIGHTMARE ON ELM STREET 4 THE DREAM MASTER'\n",
    "omdb_failures_df.at[58,'Query_Title'] = 'DIVINE SECRETS OF THE YA-YA SISTERHOOD'\n",
    "omdb_failures_df.at[59,'Query_Title'] = 'THE CONJURING 2'\n",
    "omdb_failures_df.at[60,'Query_Title'] = 'AUSTIN POWERS INTERNATIONAL MAN OF MYSTERY'\n",
    "omdb_failures_df.at[61,'Query_Title'] = 'Halloween H20: 20 Years Later'\n",
    "omdb_failures_df.at[62,'Query_Title'] = 'KILL BILL Vol. 1'\n",
    "omdb_failures_df.at[63,'Query_Title'] = 'PRINCE OF PERSIA: THE SANDS OF TIME'\n",
    "omdb_failures_df.at[64,'Query_Title'] = 'A NIGHTMARE ON ELM STREET 3'\n",
    "omdb_failures_df.at[65,'Query_Title'] = 'PERCY JACKSON & THE OLYMPIANS'\n",
    "omdb_failures_df.at[66,'Query_Title'] = 'BARNYARD'\n",
    "omdb_failures_df.at[67,'Query_Title'] = 'PLANES'\n",
    "omdb_failures_df.at[68,'Query_Title'] = 'CITY SLICKERS II'\n",
    "omdb_failures_df.at[69,'Query_Title'] = \"DON'T BREATHE\"\n",
    "omdb_failures_df.at[70,'Query_Title'] = 'JOHN WICK CHAPTER 2'\n",
    "omdb_failures_df.at[71,'Query_Title'] = 'FRIDAY THE 13TH: THE FINAL CHAPTER'\n",
    "omdb_failures_df.at[72,'Query_Title'] = 'tt0080919'\n",
    "omdb_failures_df.at[73,'Query_Title'] = \"CAN'T BUY ME LOVE\"\n",
    "omdb_failures_df.at[74,'Query_Title'] = \"A MADEA FAMILY FUNERAL\"\n",
    "omdb_failures_df.at[75,'Query_Title'] = 'tt0086352'\n",
    "omdb_failures_df.at[76,'Query_Title'] = 'QUEST FOR FIRE'\n",
    "omdb_failures_df.at[77,'Query_Title'] = 'tt0083628'\n",
    "omdb_failures_df.at[78,'Query_Title'] = 'tt0081760'\n",
    "omdb_failures_df.at[79,'Query_Title'] = 'tt0088885'\n",
    "omdb_failures_df.at[80,'Query_Title'] = 'tt0081439'\n",
    "omdb_failures_df.at[81,'Query_Title'] = 'FRIDAY THE 13TH A NEW BEGINNING'\n",
    "omdb_failures_df.at[82,'Query_Title'] = \"A NIGHTMARE ON ELM STREET 2 FREDDY'S REVENGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running first set of failures\n",
    "params = {\"type\": \"movie\", \"apikey\": OMB_api_key}\n",
    "url = \"http://www.omdbapi.com/?t=&y=\"\n",
    "count = 0\n",
    "for index, row in omdb_failures_df.iterrows():\n",
    "    params[\"t\"] = row[\"Query_Title\"]\n",
    "    params[\"y\"] = row[\"Year Released (Domestic)\"]\n",
    "    response = requests.get(url, params).json()\n",
    "    if response['Response'] == 'True':\n",
    "        try:\n",
    "            omdb_failures_df.loc[index, 'Awards'] = response['Awards']\n",
    "            omdb_failures_df.loc[index, 'Metascore'] = response['Metascore']\n",
    "            omdb_failures_df.loc[index, 'IMDB'] = response['imdbRating']\n",
    "            omdb_failures_df.loc[index, 'Rotten Tomatoes'] = response['Ratings'][1]['Value']\n",
    "            omdb_failures_df.loc[index, 'Rated'] = response['Rated']\n",
    "            omdb_failures_df.loc[index, 'Director'] = response['Director']\n",
    "            omdb_failures_df.loc[index, 'Runtime'] = response['Runtime']\n",
    "            omdb_failures_df.loc[index, 'Country'] = response['Country']\n",
    "        except:\n",
    "            omdb_failures_df = omdb_failures_df.drop(count)\n",
    "            print(f'{row.Query_Title.upper()} has missing data')\n",
    "    else:\n",
    "        print(f'{row.Query_Title.upper()} was not found')\n",
    "        omdb_failures_df = omdb_failures_df.drop(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(omdb_failures_df.shape)\n",
    "omdb_failures_df.tail(50)\n",
    "omdb_failures_df = omdb_failures_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(omdb_failures_df.shape)\n",
    "omdb_failures_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing failures to file\n",
    "omdb_failures_df.to_csv('DataFiles/OMDB_Failures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running second set of failures on imdb id - Couldn't get this to work so dumping\n",
    "\n",
    "# TT0089050 was not found\n",
    "# TT0087355 was not found\n",
    "# TT0113676 was not found\n",
    "# TT0098484 was not found\n",
    "# TT0370263 was not found\n",
    "# TT0080919 was not found\n",
    "# TT0086352 was not found\n",
    "# TT0083628 was not found\n",
    "# TT0081760 was not found\n",
    "# TT0088885 was not found\n",
    "# TT0081439 was not found\n",
    "\n",
    "# params = {\"type\": \"movie\", \"apikey\": OMB_api_key}\n",
    "# url = \"http://www.omdbapi.com/?i=&y=\"\n",
    "# count = 0\n",
    "# for index, row in omdb_failures2_df.iterrows():\n",
    "#     params[\"i\"] = row[\"Query_Title\"]\n",
    "#     params[\"y\"] = row[\"Year Released (Domestic)\"]\n",
    "#     response = requests.get(url, params).json()\n",
    "#     if response['Response'] == 'True':\n",
    "#         try:\n",
    "#             omdb_failures2_df.loc[index, 'OMDB Title'] = response['Title']\n",
    "#             omdb_failures2_df.loc[index, 'Awards'] = response['Awards']\n",
    "#             omdb_failures2_df.loc[index, 'Metascore'] = response['Metascore']\n",
    "#             omdb_failures2_df.loc[index, 'IMDB'] = response['imdbRating']\n",
    "#             omdb_failures2_df.loc[index, 'Rotten Tomatoes'] = response['Ratings'][1]['Value']\n",
    "#             omdb_failures2_df.loc[index, 'Rated'] = response['Rated']\n",
    "#             omdb_failures2_df.loc[index, 'Director'] = response['Director']\n",
    "#             omdb_failures2_df.loc[index, 'Runtime'] = response['Runtime']\n",
    "#             omdb_failures2_df.loc[index, 'Country'] = response['Country']\n",
    "#         except:\n",
    "#             omdb_failures_df = omdb_failures2_df.drop(count)\n",
    "#             print(f'{row.Query_Title.upper()} has missing data')\n",
    "#     else:\n",
    "#         print(f'{row.Query_Title.upper()} was not found')\n",
    "#         omdb_failures_df = omdb_failures2_df.drop(count)\n",
    "#     count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating successes & failures\n",
    "# OMDB_Final_df = pd.merge(omdb_failures_df, omdb_successes_df, on='')\n",
    "frames = [omdb_failures_df, omdb_successes_df]\n",
    "OMDB_Final_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OMDB_Final_df.shape)\n",
    "OMDB_Final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMDB_Final_df.to_csv('DataFiles/OMDB_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NICOLE'S CLEANUP CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jason's code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 2 files one for data already populated (clean_test_df) for John to work with Analysis\n",
    "# the second is for Marianne and I to parse through and find on OMDB\n",
    "# clean_test_df = omdb_df.dropna()\n",
    "# clean_test_df.head(50)\n",
    "# clean_test_df.to_csv('DataFiles/clean_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_be_cleaned_df = omdb_df[pd.isnull(omdb_df['Awards'])]\n",
    "# to_be_cleaned_df.head(50)\n",
    "# to_be_cleaned_df.shape\n",
    "# to_be_cleaned_df.to_csv('DataFiles/to_be_clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_be_clean_data = pd.read_csv('DataFiles/to_be_clean_data.csv')\n",
    "# to_be_clean_data\n",
    "# jason_cleanup_df= to_be_clean_data.head(75)\n",
    "# jason_cleanup_df\n",
    "#create a new dataframe with the movies that actually need cleaning\n",
    "# j_cleaning_df = jason_cleanup_df[pd.isnull(jason_cleanup_df['Metascore'])&pd.isnull(jason_cleanup_df['IMDB'])]\n",
    "# j_cleaning_df\n",
    "# j_cleaning_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j_cleaning_df.at[[10],'Query_Title'] = \"The battle of the five armies\"\n",
    "# j_cleaning_df\n",
    "\n",
    "# j_cleaning_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out lines that were mistakenly included into the nan dataset based on awards stats\n",
    "# and save for re-merging later \n",
    "# j_clean_awards_df = jason_cleanup_df.dropna(subset=['IMDB']) #'Metascore']), 'IMDB'])\n",
    "# j_clean_awards_df\n",
    "# j_clean_awards_df.shape\n",
    "\n",
    "# jason_cleanup_df.to_csv('DataFiles/jason_cleanup_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = j_cleaning_df.append(j_clean_awards_df, ignore_index=True)\n",
    "# new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.to_csv('DataFiles/jason_cleanup_done_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jason's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marianne's code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the last half of data to be cleaned up, based on 149 total rows of data\n",
    "# cleaning_df = pd.read_csv('DataFiles/to_be_clean_data.csv')\n",
    "# second_half_df = cleaning_df.tail(74)\n",
    "# second_half_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out lines that were mistakenly included into the nan dataset based on awards stats\n",
    "# and save for re-merging later \n",
    "\n",
    "# m_clean_awards_df = second_half_df.dropna(subset=['IMDB'])\n",
    "# m_clean_awards_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe with the movies that actually need cleaning\n",
    "# m_cleaning_df = second_half_df[pd.isnull(second_half_df['IMDB'])]\n",
    "\n",
    "# m_cleaning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overwrite cells with new query inputs\n",
    "# m_cleaning_df.at[75,'Query_Title'] = 'Divine Secrets'\n",
    "# m_cleaning_df.at[76,'Query_Title'] = 'conjuring 2'\n",
    "# m_cleaning_df.at[78,'Query_Title'] = 'austin powers'\n",
    "# m_cleaning_df.at[79,'Query_Title'] = 'Halloween H20'\n",
    "# m_cleaning_df.at[80,'Query_Title'] = 'Kill Bill: Vol. 1'\n",
    "# m_cleaning_df.at[82,'Query_Title'] = 'Prince of Persia'\n",
    "# m_cleaning_df.at[85,'Query_Title'] = 'Nightmare On Elm Street 3'\n",
    "# m_cleaning_df.at[87,'Query_Title'] = 'Percy Jackson & the Olympians'\n",
    "# m_cleaning_df.at[90,'Query_Title'] = 'Barnyard'\n",
    "# m_cleaning_df.at[91,'Query_Title'] = 'Planes'\n",
    "# m_cleaning_df.at[92,'Query_Title'] = 'City Slickers II'\n",
    "# m_cleaning_df.at[99,'Query_Title'] = \"don't Breathe\"\n",
    "# m_cleaning_df.at[100,'Query_Title'] = 'John Wick Chapter 2'\n",
    "# m_cleaning_df.at[104,'Query_Title'] = 'Friday the 13th: The Final Chapter'\n",
    "# m_cleaning_df.at[124,'Query_Title'] = \"can't buy me love\"\n",
    "# m_cleaning_df.at[125,'Query_Title'] = 'madea family funeral'\n",
    "# m_cleaning_df.at[146,'Query_Title'] = 'A Nightmare on Elm Street 2'\n",
    "\n",
    "# m_cleaning_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-run the API for the updated query names\n",
    "# params = {\"type\": \"movie\",\"apikey\": OMB_api_key}\n",
    "# url = \"http://www.omdbapi.com/?t=\"\n",
    "# count = 0\n",
    "# for index, row in m_cleaning_df.iterrows():\n",
    "#     params['t'] = row[\"Query_Title\"]\n",
    "#     params['y'] = row[\"Year Released (Domestic)\"]\n",
    "#     response = requests.get(url, params).json()\n",
    "#     if response['Response'] == 'True':\n",
    "#         try:\n",
    "#             m_cleaning_df.loc[index, 'Awards'] = response['Awards']\n",
    "#             m_cleaning_df.loc[index, 'Metascore'] = response['Metascore']\n",
    "#             m_cleaning_df.loc[index, 'IMDB'] = response['imdbRating']\n",
    "#             m_cleaning_df.loc[index, 'Rotten Tomatoes'] = response['Ratings'][1]['Value']\n",
    "#             m_cleaning_df.loc[index, 'Rated'] = response['Rated']\n",
    "#             m_cleaning_df.loc[index, 'Director'] = response['Director']\n",
    "#             m_cleaning_df.loc[index, 'Runtime'] = response['Runtime']\n",
    "#             m_cleaning_df.loc[index, 'Country'] = response['Country']\n",
    "#         except:\n",
    "#             print(f'{row.Query_Title.upper()} (row {count}) has missing data')\n",
    "#         count += 1\n",
    "#     else:\n",
    "#         print(f'{row.Query_Title.upper()} (row {count}) was not found')\n",
    "#         count += 1\n",
    "\n",
    "# m_cleaning_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate both of marianne's dataframes back together\n",
    "\n",
    "# frames = [m_clean_awards_df, m_cleaning_df]\n",
    "# m_complete_df = pd.concat(frames)\n",
    "\n",
    "# #save the completed data to a csv for later concatenation\n",
    "# m_complete_df.to_csv('DataFiles/marianne_cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the previously saved csvs into dataframes\n",
    "\n",
    "#import jason's data\n",
    "# jason_df = pd.read_csv('DataFiles/jason_cleanup_done_df.csv')\n",
    "\n",
    "# #import marianne's data\n",
    "# marianne_df = pd.read_csv('DataFiles/marianne_cleaned_data.csv')\n",
    "\n",
    "# #import the clean data separated earlier\n",
    "# cleaned_df = pd.read_csv('DataFiles/clean_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite the remaining query titles not delivering results\n",
    "\n",
    "# jason_df.at[34,'Query_Title'] = 'greystoke'\n",
    "# jason_df.at[35,'Query_Title'] = 'mousehunt'\n",
    "# jason_df.at[36,'Query_Title'] = 'nice dreams'\n",
    "# jason_df.at[49,'Query_Title'] = 'mr & mrs smith'\n",
    "# jason_df.at[65,'Query_Title'] = 'Blade II'\n",
    "# jason_df.at[73,'Query_Title'] = 'Friday the 13th Part III'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run cleaned data through the API\n",
    "# params = {\"type\": \"movie\",\"apikey\": OMB_api_key}\n",
    "# url = \"http://www.omdbapi.com/?t=\"\n",
    "# count = 0\n",
    "# for index, row in jason_df.iterrows():\n",
    "#     params['t'] = row[\"Query_Title\"]\n",
    "#     params['y'] = row[\"Year Released (Domestic)\"]\n",
    "#     response = requests.get(url, params).json()\n",
    "#     if response['Response'] == 'True':\n",
    "#         try:\n",
    "#             jason_df.loc[index, 'Awards'] = response['Awards']\n",
    "#             jason_df.loc[index, 'Metascore'] = response['Metascore']\n",
    "#             jason_df.loc[index, 'IMDB'] = response['imdbRating']\n",
    "#             jason_df.loc[index, 'Rotten Tomatoes'] = response['Ratings'][1]['Value']\n",
    "#             jason_df.loc[index, 'Rated'] = response['Rated']\n",
    "#             jason_df.loc[index, 'Director'] = response['Director']\n",
    "#             jason_df.loc[index, 'Runtime'] = response['Runtime']\n",
    "#             jason_df.loc[index, 'Country'] = response['Country']\n",
    "#         except:\n",
    "#             print(f'{row.Query_Title.upper()} (row {count}) has missing data')\n",
    "#         count += 1\n",
    "#     else:\n",
    "#         print(f'{row.Query_Title.upper()} (row {count}) was not found')\n",
    "#         count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate marianne and jason's cleaned data with the clean data from earlier\n",
    "\n",
    "# frames = [jason_df, marianne_df, cleaned_df]\n",
    "# cleaned_query_titles_df = pd.concat(frames)\n",
    "\n",
    "#output the cleaned query titles in a csv. \n",
    "#note: awards need to be cleaned next\n",
    "# cleaned_query_titles_df.to_csv('DataFiles/queries_cleaned_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the csv to clean/update movie titles\n",
    "# award_cleaning_df = pd.read_csv('DataFiles/queries_cleaned_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# award_cleaning_df.head()\n",
    "# award_cleaning_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all movies with NaN in the awards column\n",
    "# awardMovies_df = award_cleaning_df.dropna(subset=['Awards'])\n",
    "\n",
    "# #insert column for Oscars Won\n",
    "# awardMovies_df.insert(loc=11, column='Oscars Won', value=\"\")\n",
    "\n",
    "# # #limit to only Awards and Oscars Won columns\n",
    "# awardMovies_df = awardMovies_df[['Title', 'Awards', 'Oscars Won']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the awards column, the description of oscar winners begins with the word \"won\"\n",
    "#find oscar winners by finding the word 'won'\n",
    "OMDB_Final_df.loc[OMDB_Final_df['Awards'].str.contains('Won', regex=False) == True, 'Oscars Won'] = 'Yes'\n",
    "OMDB_Final_df.loc[OMDB_Final_df['Awards'].str.contains('Won', regex=False) == False, 'Oscars Won'] = 'No'\n",
    "\n",
    "OMDB_Final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter down to movies that have won an oscar\n",
    "oscar_df = OMDB_Final_df.loc[OMDB_Final_df['Oscars Won'] == 'Yes']\n",
    "oscar_df.reset_index(drop=True, inplace=True)\n",
    "print(oscar_df.shape)\n",
    "oscar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pull the number of oscars won, save in new column\n",
    "for index, row in oscar_df.iterrows():\n",
    "#     string = \n",
    "    oscar_df.loc[index, \"Number Oscars Won\"] = re.findall('\\d+', oscar_df.loc[index, \"Awards\"])[0]\n",
    "\n",
    "oscar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the Awards column from the oscar_df to avoid duplicating in the final dataframe\n",
    "oscar_df = oscar_df[['Title', 'Year Released (Domestic)', 'Number Oscars Won']]\n",
    "\n",
    "#re-merge the awards into the dataframe\n",
    "FINAL_CLEANED_DF = pd.merge(OMDB_Final_df, oscar_df, \n",
    "                      how=\"left\", on='Title')\n",
    "\n",
    "FINAL_CLEANED_DF = pd.merge(OMDB_Final_df, oscar_df, \n",
    "                      how=\"left\", on=['Title', 'Year Released (Domestic)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all NaNs in the number oscars won column with zero\n",
    "FINAL_CLEANED_DF['Number Oscars Won'] = FINAL_CLEANED_DF['Number Oscars Won'].fillna(0)\n",
    "\n",
    "#replace all NaNs in the oscars won column with 'no'\n",
    "FINAL_CLEANED_DF['Oscars Won'] = FINAL_CLEANED_DF['Oscars Won'].fillna('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add Oscar percentage columns\n",
    "# FINAL_CLEANED_DF['Percent Oscar Wins'] = FINAL_CLEANED_DF['Number Oscars Won'] / \\\n",
    "# FINAL_CLEANED_DF['Total Oscars Awarded in Year'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FINAL_CLEANED_DF.shape)\n",
    "FINAL_CLEANED_DF.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_CLEANED_DF = FINAL_CLEANED_DF[['Title', 'Domestic Release Date',\n",
    "       'Year Released (Domestic)', 'Month Released (Domestic)',\n",
    "       'Infl. Adj. Dom. Box Office', 'Domestic Box Office', 'Genre', 'Oscars Won', 'Number Oscars Won',\n",
    "       'Total Oscars Awarded in Year', 'Awards',\n",
    "       'Metascore', 'IMDB', 'Rotten Tomatoes', 'Rated', 'Director', 'Runtime',\n",
    "       'Theatrical Distributor', 'Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_CLEANED_DF.to_csv('DataFiles/FINAL_CLEANED_DF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_CLEANED_DF = pd.read_csv('DataFiles/FINAL_CLEANED_DF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FINAL_CLEANED_DF.shape)\n",
    "FINAL_CLEANED_DF.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marianne's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT STEPS\n",
    "# Pull out NaN values from omdb_df and resave - DONE\n",
    "# Create new dataframes with only NaN values & figure out how to make successful API calls on them - DONE\n",
    "    # (might be a series of datframes & API calls after tweaking key words or maybe adding variable for year)\n",
    "# Pull out oscar wins - DONE\n",
    "# Save & review final dataframe - SAVED, ready for review with group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
